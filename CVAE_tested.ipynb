{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T18:04:32.404256Z",
     "start_time": "2019-01-06T18:04:32.017004Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T18:04:32.409761Z",
     "start_time": "2019-01-06T18:04:32.404256Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x, layerName = 'default'):\n",
    "        # Do your print / debug stuff here\n",
    "        print(layerName+': {}'.format(x.shape))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T18:04:32.755940Z",
     "start_time": "2019-01-06T18:04:32.411786Z"
    }
   },
   "outputs": [],
   "source": [
    "nc = 4\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, nz, nBatch, nChannels, W, H, _channel):\n",
    "        super(CVAE, self).__init__()\n",
    "\n",
    "        self.nz = nz\n",
    "        self.nBatch = nBatch\n",
    "        self.nChannels = nChannels\n",
    "        self.W = W\n",
    "        self.H = H\n",
    "        self._channel = _channel\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            \n",
    "#             [input -> (1) -> (2) -> (3) -> output]\n",
    "            nn.Conv3d(nChannels, 16, (3, 3, 3), stride=(1, 1, 1), padding=(1,1,1),bias=False),\n",
    "            PrintLayer(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose3d(16, 8, (3,3,3), stride=(1,1,1), padding=(1,1,1), bias=False),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(16*nBatch*W*H*_channel, nChannels)\n",
    "        self.fc21 = nn.Linear(8, nz)\n",
    "        self.fc22 = nn.Linear(8, nz)\n",
    "\n",
    "        self.fc3 = nn.Linear(nz, 8)\n",
    "        self.fc4 = nn.Linear(8, 16*nBatch*W*H*_channel)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        conv = self.encoder(x);\n",
    "        print(\"encode conv\", conv.size())\n",
    "        h1 = self.fc1(conv.view(-1, 16*self.nBatch*self.W*self.H*self._channel))\n",
    "        print(\"encode h1\", h1.size())\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        deconv_input = self.fc4(h3)\n",
    "        print(\"deconv_input\", deconv_input.size())\n",
    "        deconv_input = deconv_input.view(self.nBatch,16,self.W,self.H,self._channel)\n",
    "        print(\"deconv_input\", deconv_input.size())\n",
    "        return self.decoder(deconv_input)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "#         if self.have_cuda:\n",
    "#         eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "#         else:\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"x\", x.size())\n",
    "        mu, logvar = self.encode(x)\n",
    "        print(\"mu, logvar\", mu.size(), logvar.size())\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        print(\"z\", z.size())\n",
    "        decoded = self.decode(z)\n",
    "        print(\"decoded\", decoded.size())\n",
    "        return decoded, mu, logvar\n",
    "      \n",
    "# build model\n",
    "model = CVAE(4, 3, 8, 240, 240, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T18:04:33.222493Z",
     "start_time": "2019-01-06T18:04:32.757758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([3, 8, 240, 240, 1])\n",
      "default: torch.Size([3, 16, 240, 240, 1])\n",
      "encode conv torch.Size([3, 16, 240, 240, 1])\n",
      "encode h1 torch.Size([1, 8])\n",
      "mu, logvar torch.Size([1, 4]) torch.Size([1, 4])\n",
      "z torch.Size([1, 4])\n",
      "deconv_input torch.Size([1, 2764800])\n",
      "deconv_input torch.Size([3, 16, 240, 240, 1])\n",
      "decoded torch.Size([3, 8, 240, 240, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aed35eb2a1c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m240\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 8, 240, 240, 1)\n",
    "output,_,_ = model(input)\n",
    "model.modules[2].output:size()\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
